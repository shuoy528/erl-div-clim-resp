{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions and Map Visualization\n",
    "\n",
    "Date: 09/01/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Map\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.express as px\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in NPP, GPP, Yield, and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat(file_name, crop, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Read in a set of data sets and concatenate them into one dataframe.\n",
    "    \"\"\"\n",
    "    cwd = os.path.dirname(os.getcwd())\n",
    "    filename = 'Data_original\\\\' + file_name + str(start_year) + '_' + crop + '.csv'\n",
    "    location = os.path.join(cwd, filename)\n",
    "    output_df = pd.read_csv(location, header=0)\n",
    "\n",
    "    for y in range(start_year+1, end_year+1):\n",
    "        filename = 'Data_original\\\\' + file_name + str(y) + '_' + crop + '.csv'\n",
    "        location = os.path.join(cwd, filename)\n",
    "        df = pd.read_csv(location, header=0)\n",
    "        output_df =  pd.concat([output_df, df], ignore_index=True)\n",
    "        \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in yield data by county.\n",
    "cwd = os.path.dirname(os.getcwd())\n",
    "filename = 'Data_original\\\\corn_yield_data.csv'\n",
    "location = os.path.join(cwd, filename)\n",
    "yield_df = pd.read_csv(location, header=0)\n",
    "yield_df = yield_df[['year', 'state_ansi', 'county_ansi', 'Value']].copy()\n",
    "\n",
    "# Read in GPP data by county.\n",
    "GPP_acc = read_concat('GPPintegral', 'Corn', 2001, 2020)\n",
    "GPP_acc.drop(columns=['system:index', '.geo', 'QC_sum'], inplace=True)\n",
    "GPP_acc.dropna(subset=['GPP_sum'], inplace=True)\n",
    "GPP_acc.reset_index(drop=True, inplace=True)\n",
    "corn_df = GPP_acc.merge(yield_df, \n",
    "                        left_on=['STATEFP', 'COUNTYFP', 'Year'], \n",
    "                        right_on=['state_ansi', 'county_ansi', 'year'], \n",
    "                        how='outer')\n",
    "\n",
    "# Read in NPP data by county.\n",
    "NPP_acc = read_concat('NPPintegral', 'Corn', 2001, 2019)\n",
    "NPP_acc = NPP_acc[['STATEFP', 'COUNTYFP', 'Year', 'annualNPP_sum']]\n",
    "NPP_acc.dropna(subset=['annualNPP_sum'], inplace=True)\n",
    "NPP_acc.reset_index(drop=True, inplace=True)\n",
    "corn_df = corn_df.merge(NPP_acc, \n",
    "                        on=['STATEFP', 'COUNTYFP', 'Year'], \n",
    "                        how='outer')\n",
    "\n",
    "# Keep only useful variables\n",
    "corn_df.Year.fillna(corn_df.year, inplace=True)\n",
    "corn_df.COUNTYFP.fillna(corn_df.county_ansi, inplace=True)\n",
    "corn_df.STATEFP.fillna(corn_df.state_ansi, inplace=True)\n",
    "corn_df.drop(columns=['year', 'state_ansi', 'county_ansi'], inplace=True)\n",
    "corn_df.columns = ['AFFGEOID', 'ALAND', 'AWATER', 'COUNTYFP', 'COUNTYNS', 'CropLand',\n",
    "                   'GEOID', 'GPP_integral', 'LSAD', 'NAME', 'STATEFP', 'Year', 'Yield',\n",
    "                   'NPP_integral']\n",
    "corn_df.drop(columns=['AFFGEOID', 'ALAND', 'AWATER', 'COUNTYNS', 'LSAD'], \n",
    "             inplace=True)\n",
    "\n",
    "# Read in weather data by county.\n",
    "filename = 'Data_original\\\\corn_weather.csv'\n",
    "location = os.path.join(cwd, filename)\n",
    "weather_df_corn = pd.read_csv(location, header=0)\n",
    "corn_df = corn_df.merge(weather_df_corn, \n",
    "                        left_on=['STATEFP', 'COUNTYFP', 'Year'], \n",
    "                        right_on=['statefp', 'countyfp', 'year'], \n",
    "                        how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Random Forest Regression\n",
    "#### 2.1. CUE\n",
    "##### 2.1.1. Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "proportion_test = 0.4\n",
    "seed_num = 159\n",
    "# Tuning range\n",
    "max_depth = range(5, 31)\n",
    "num_trees = [100, 500, 1000]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "var_list_rf = ['GPP_integral', 'NPP_integral', 'Yield', \n",
    "               'Year', 'prcp', 'gdd', 'edd']\n",
    "df_rf = corn_df.loc[:, var_list_rf].dropna(\n",
    "    subset=['GPP_integral', 'NPP_integral'], how='any').copy()\n",
    "df_rf['CUE'] = df_rf['NPP_integral']/df_rf['GPP_integral']\n",
    "\n",
    "# Mask the missing data\n",
    "target = 'CUE'\n",
    "missing_mask = ~ df_rf[target].isna()\n",
    "df_rf = df_rf[missing_mask]\n",
    "missing_mask = ~ df_rf['gdd'].isna()\n",
    "df_rf = df_rf[missing_mask]\n",
    "data_train, data_test = train_test_split(df_rf, \n",
    "                                         test_size=proportion_test, \n",
    "                                         random_state=seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to find the optimal max depth for each tree\n",
    "features = data_train.columns\n",
    "features_select = list(set(features) - \n",
    "                       set([target, 'GPP_integral', 'NPP_integral', 'Yield']))\n",
    "X = data_train[features_select].values\n",
    "y = data_train[target].values\n",
    "result_test = {}\n",
    "result_train = {}\n",
    "for t in num_trees:\n",
    "    for i in max_depth:\n",
    "        clf = RandomForestRegressor(n_estimators=t, \n",
    "                                    max_depth=i, \n",
    "                                    max_features=\"sqrt\")\n",
    "        scores = cross_validate(clf, X, y, \n",
    "                                cv=10, \n",
    "                                return_train_score=True)\n",
    "        result_test[(i,t)] = scores['test_score'].mean()\n",
    "        result_train[(i,t)] = scores['train_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.DataFrame(result_test, index=[0])\n",
    "result_test = result_test.transpose()\n",
    "result_train = pd.DataFrame(result_train, index=[0])\n",
    "result_train = result_train.transpose()\n",
    "optimal_depth = result_test.idxmax()[0][0]\n",
    "optimal_num_trees = result_test.idxmax()[0][1]\n",
    "r1 = pd.DataFrame(result_test).reset_index()\n",
    "r2 = pd.DataFrame(result_train).reset_index()\n",
    "r1.columns = ['max_depth', 'num_trees', 'Rsquared']\n",
    "r2.columns = ['max_depth', 'num_trees', 'Rsquared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "plt.plot(r2[\"max_depth\"], r2[\"Rsquared\"], \n",
    "         'o',color='blue',label='Train')\n",
    "plt.plot(r1[\"max_depth\"], r1[\"Rsquared\"], \n",
    "         'o',color='red',label='Test')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Average R-squared')\n",
    "plt.legend()\n",
    "filename = 'figures\\\\training_max_depth_corn_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "plt.plot(r2[\"num_trees\"], r2[\"Rsquared\"], \n",
    "         'o',color='blue',label='Train')\n",
    "plt.plot(r1[\"num_trees\"], r1[\"Rsquared\"], \n",
    "         'o',color='red',label='Test')\n",
    "plt.xlabel('num_trees')\n",
    "plt.ylabel('Average R-squared')\n",
    "plt.legend()\n",
    "filename = 'figures\\\\training_num_trees_corn_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2. Random forest model using tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the optimal max depth, we fit a random forest model \n",
    "# with the training data set, and get the test accuracy.\n",
    "test_X = data_test[features_select].values\n",
    "test_y = data_test[target].values\n",
    "clf = RandomForestRegressor(n_estimators=optimal_num_trees, \n",
    "                            max_depth=optimal_depth, \n",
    "                            max_features=\"sqrt\")\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Test accuracy\n",
    "train_score = clf.score(X,y)\n",
    "hold_score = clf.score(test_X, test_y)\n",
    "print('Training R squared: {:.2f}'.format(train_score))\n",
    "print('Testing R squared: {:.2f}'.format(hold_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(test_X)\n",
    "predict_train = clf.predict(X)\n",
    "df_test = pd.DataFrame(predict_test)\n",
    "df_train = pd.DataFrame(predict_train)\n",
    "df_test.columns = [\"predicted_value\"]\n",
    "df_train.columns = [\"predicted_value\"]\n",
    "df_test['true_value'] = test_y\n",
    "df_train['true_value'] = y\n",
    "df_test['dataset'] = 'test'\n",
    "df_train['dataset'] = 'train'\n",
    "df_figure = pd.concat([df_test, df_train], ignore_index=True)\n",
    "RMSE_train = round(np.sqrt(np.mean(np.power(\n",
    "    df_train['true_value']-df_train['predicted_value'],2))),2)\n",
    "RMSE_test = round(np.sqrt(np.mean(\n",
    "    np.power(df_test['true_value']-df_test['predicted_value'],2))),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfig, axs = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axs[1, 0].scatter(df_train['true_value'], \n",
    "            df_train['predicted_value'], \n",
    "            color='blue', \n",
    "            label='training data', \n",
    "            alpha=0.2)\n",
    "axs[1, 0].scatter(df_test['true_value'], \n",
    "            df_test['predicted_value'], \n",
    "            color='red', \n",
    "            label='testing data', \n",
    "            alpha=0.2)\n",
    "axs[1, 0].set_xlabel('True Value', fontsize = 25)\n",
    "axs[1, 0].set_ylabel('Predicted Value', fontsize = 25)\n",
    "axs[1, 0].legend(loc='lower right', fontsize = 25)\n",
    "axs[1, 0].set_title('(b-1) CUE True Values Vs. Predictions', \n",
    "                    fontsize = 25)\n",
    "axs[1, 0].plot([0, 1.5], [0, 1.5], color = 'black', linewidth = 2)\n",
    "axs[1, 0].text(-0.05, 1.12, 'R-squared for training data: '+ \n",
    "              str(round(train_score,4)) +\n",
    "              '\\nRMSE for training data: ' +\n",
    "              str(RMSE_train) +\n",
    "              '\\nR-squared for testing data: ' +\n",
    "              str(round(hold_score,4)) +\n",
    "              '\\nRMSE for testing data: ' +\n",
    "              str(RMSE_test), fontsize=25)\n",
    "plt.rc('xtick', labelsize=25)\n",
    "plt.rc('ytick', labelsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "importances = clf.feature_importances_\n",
    "idx = np.argsort(importances)\n",
    "axs[1, 1].set_title('(b-2) CUE Feature importance', \n",
    "                    fontsize = 25)\n",
    "axs[1, 1].barh(range(len(idx)), \n",
    "               importances[idx], \n",
    "               color='blue')\n",
    "axs[1, 1].set_yticks(range(len(idx)), \n",
    "                     [features_select[i] for i in idx])\n",
    "axs[1, 1].set_xlabel('Mean Impurity Decrease within Each Tree', fontsize = 25)\n",
    "axs[1, 1].set_ylabel('Feature', fontsize = 25)\n",
    "outputfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Yield\n",
    "##### 2.2.1. Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "proportion_test = 0.4\n",
    "seed_num = 1237\n",
    "# Tuning range\n",
    "max_depth = range(5, 31)\n",
    "num_trees = [100, 500, 1000]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "var_list_rf = ['GPP_integral', 'NPP_integral', 'Yield', \n",
    "               'Year', 'prcp', 'gdd', 'edd']\n",
    "df_rf = corn_df.loc[:, var_list_rf].dropna(\n",
    "    subset=['GPP_integral', 'NPP_integral'], how='any').copy()\n",
    "\n",
    "# Mask the missing data\n",
    "target = 'Yield'\n",
    "missing_mask = ~ df_rf[target].isna()\n",
    "df_rf = df_rf[missing_mask]\n",
    "missing_mask = ~ df_rf['gdd'].isna()\n",
    "df_rf = df_rf[missing_mask]\n",
    "data_train, data_test = train_test_split(df_rf, \n",
    "                                         test_size=proportion_test, \n",
    "                                         random_state=seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to find the optimal max depth for each tree\n",
    "features = data_train.columns\n",
    "features_select = list(set(features) - \n",
    "                       set([target, 'GPP_integral', 'NPP_integral']))\n",
    "X = data_train[features_select].values\n",
    "y = data_train[target].values\n",
    "result_test = {}\n",
    "result_train = {}\n",
    "for t in num_trees:\n",
    "    for i in max_depth:\n",
    "        clf = RandomForestRegressor(n_estimators=t, \n",
    "                                    max_depth=i, \n",
    "                                    max_features=\"sqrt\")\n",
    "        scores = cross_validate(clf, X, y, \n",
    "                                cv=10, \n",
    "                                return_train_score=True)\n",
    "        result_test[(i,t)] = scores['test_score'].mean()\n",
    "        result_train[(i,t)] = scores['train_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.DataFrame(result_test, index=[0])\n",
    "result_test = result_test.transpose()\n",
    "result_train = pd.DataFrame(result_train, index=[0])\n",
    "result_train = result_train.transpose()\n",
    "optimal_depth = result_test.idxmax()[0][0]\n",
    "optimal_num_trees = result_test.idxmax()[0][1]\n",
    "r1 = pd.DataFrame(result_test).reset_index()\n",
    "r2 = pd.DataFrame(result_train).reset_index()\n",
    "r1.columns = ['max_depth', 'num_trees', 'Rsquared']\n",
    "r2.columns = ['max_depth', 'num_trees', 'Rsquared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "plt.plot(r2[\"max_depth\"], r2[\"Rsquared\"], \n",
    "         'o',color='blue',label='Train')\n",
    "plt.plot(r1[\"max_depth\"], r1[\"Rsquared\"], \n",
    "         'o',color='red',label='Test')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Average R-squared')\n",
    "plt.legend()\n",
    "filename = 'figures\\\\training_max_depth_corn_yield.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "plt.plot(r2[\"num_trees\"], r2[\"Rsquared\"], \n",
    "         'o',color='blue',label='Train')\n",
    "plt.plot(r1[\"num_trees\"], r1[\"Rsquared\"], \n",
    "         'o',color='red',label='Test')\n",
    "plt.xlabel('num_trees')\n",
    "plt.ylabel('Average R-squared')\n",
    "plt.legend()\n",
    "filename = 'figures\\\\training_num_trees_corn_yield.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2. Random forest model using tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the optimal max depth, we fit a random forest model \n",
    "# with the training data set, and get the test accuracy.\n",
    "test_X = data_test[features_select].values\n",
    "test_y = data_test[target].values\n",
    "clf = RandomForestRegressor(n_estimators=optimal_num_trees, \n",
    "                            max_depth=optimal_depth, \n",
    "                            max_features=\"sqrt\")\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Test accuracy\n",
    "train_score = clf.score(X,y)\n",
    "hold_score = clf.score(test_X, test_y)\n",
    "print('Training R squared: {:.2f}'.format(train_score))\n",
    "print('Testing R squared: {:.2f}'.format(hold_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(test_X)\n",
    "predict_train = clf.predict(X)\n",
    "df_test = pd.DataFrame(predict_test)\n",
    "df_train = pd.DataFrame(predict_train)\n",
    "df_test.columns = [\"predicted_value\"]\n",
    "df_train.columns = [\"predicted_value\"]\n",
    "df_test['true_value'] = test_y\n",
    "df_train['true_value'] = y\n",
    "df_test['dataset'] = 'test'\n",
    "df_train['dataset'] = 'train'\n",
    "df_figure = pd.concat([df_test, df_train], ignore_index=True)\n",
    "RMSE_train = round(np.sqrt(np.mean(np.power(\n",
    "    df_train['true_value']-df_train['predicted_value'],2))),2)\n",
    "RMSE_test = round(np.sqrt(np.mean(\n",
    "    np.power(df_test['true_value']-df_test['predicted_value'],2))),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0, 0].scatter(df_train['true_value'], \n",
    "            df_train['predicted_value'], \n",
    "            color='blue', \n",
    "            label='training data', \n",
    "            alpha=0.2)\n",
    "axs[0, 0].scatter(df_test['true_value'], \n",
    "            df_test['predicted_value'], \n",
    "            color='red', \n",
    "            label='testing data', \n",
    "            alpha=0.2)\n",
    "axs[0, 0].set_xlabel('True Value (Bushels/Acre)', fontsize = 25)\n",
    "axs[0, 0].set_ylabel('Predicted Value (Bushels/Acre)', fontsize = 25)\n",
    "axs[0, 0].legend(loc='lower right', fontsize = 25)\n",
    "axs[0, 0].set_title('(a-1) Yield True Values Vs. Predictions', \n",
    "                    fontsize = 25)\n",
    "axs[0, 0].plot([0, 250], [0, 250], color = 'black', linewidth = 2)\n",
    "axs[0, 0].text(-8, 185, 'R-squared for training data: '+ \n",
    "              str(round(train_score,4)) +\n",
    "              '\\nRMSE for training data: ' +\n",
    "              str(RMSE_train) +\n",
    "              '\\nR-squared for testing data: ' +\n",
    "              str(round(hold_score,4)) +\n",
    "              '\\nRMSE for testing data: ' +\n",
    "              str(RMSE_test), fontsize=25)\n",
    "outputfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "importances = clf.feature_importances_\n",
    "idx = np.argsort(importances)\n",
    "axs[0, 1].set_title('(a-2) Yield Feature importance', \n",
    "                    fontsize = 25)\n",
    "axs[0, 1].barh(range(len(idx)), \n",
    "               importances[idx], \n",
    "               color='blue')\n",
    "axs[0, 1].set_yticks(range(len(idx)), \n",
    "                     [features_select[i] for i in idx])\n",
    "axs[0, 1].set_xlabel('Mean Impurity Decrease within Each Tree', fontsize = 25)\n",
    "axs[0, 1].set_ylabel('Feature', fontsize = 25)\n",
    "outputfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0,0].tick_params(axis='both', labelsize=25)\n",
    "axs[0,1].tick_params(axis='both', labelsize=25)\n",
    "axs[1,0].tick_params(axis='both', labelsize=25)\n",
    "axs[1,1].tick_params(axis='both', labelsize=25)\n",
    "outputfig.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "outputfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'figures\\\\figure_3.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "outputfig.savefig(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Map Visualization\n",
    "#### 3.1. Map Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list_yield = ['STATEFP', 'COUNTYFP', 'Yield', \n",
    "                  'Year', 'prcp', 'gdd', 'edd']\n",
    "corn_df_yield = corn_df.loc[:, var_list_yield].dropna(subset=['Yield'])\n",
    "corn_df_yield = corn_df_yield.loc[corn_df_yield.Year>2000]\n",
    "corn_counts = pd.DataFrame(corn_df_yield.groupby(['STATEFP', 'COUNTYFP']).size(), \n",
    "                           columns=['ct']).reset_index()\n",
    "corn_df_yield = corn_df_yield.merge(corn_counts, \n",
    "                                    on=['STATEFP', 'COUNTYFP'], \n",
    "                                    how='left')\n",
    "corn_df_yield = corn_df_yield.loc[corn_df_yield.ct>10,:]\n",
    "corn_df_yield['fips'] = corn_df_yield.COUNTYFP + corn_df_yield.STATEFP*1000\n",
    "corn_df_yield['fips'] = ['{0:05}'.format(int(x)) \n",
    "                         for x in corn_df_yield['fips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list_cue = ['STATEFP', 'COUNTYFP', 'GPP_integral', \n",
    "                'NPP_integral', 'Year', 'prcp', 'gdd', 'edd']\n",
    "corn_df_cue = corn_df.loc[:, var_list_cue].dropna(\n",
    "    subset=['GPP_integral', 'NPP_integral'], how='any')\n",
    "corn_counts = pd.DataFrame(corn_df_cue.groupby(['STATEFP', 'COUNTYFP']).size(), \n",
    "                           columns=['ct']).reset_index()\n",
    "corn_df_cue = corn_df_cue.merge(corn_counts, \n",
    "                                on=['STATEFP', 'COUNTYFP'], \n",
    "                                how='left')\n",
    "corn_df_cue = corn_df_cue.loc[corn_df_cue.ct>10]\n",
    "corn_df_cue['CUE'] = corn_df_cue['NPP_integral']/corn_df_cue['GPP_integral']\n",
    "corn_df_cue['fips'] = corn_df_cue.COUNTYFP + corn_df_cue.STATEFP*1000\n",
    "corn_df_cue['fips'] = ['{0:05}'.format(int(x)) \n",
    "                       for x in corn_df_cue['fips']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Corn CUE and yield visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_yield_map = pd.DataFrame(corn_df_yield.groupby('fips').mean())\n",
    "corn_yield_map.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_cue_map = pd.DataFrame(corn_df_cue.groupby('fips').mean())\n",
    "corn_cue_map.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_cue_map.CUE.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(corn_cue_map.loc[corn_cue_map.CUE>0,:], \n",
    "                    geojson=counties, locations='fips', color='CUE',\n",
    "                    color_continuous_scale=\"YlGn\",\n",
    "                    range_color=(0.388, 0.683),\n",
    "                    scope=\"usa\",\n",
    "                    labels={'CUE':'CUE'}\n",
    "                   )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\CUE.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(corn_yield_map.loc[corn_yield_map.Yield>0,:], geojson=counties, locations='fips', color='Yield',\n",
    "                           color_continuous_scale=\"YlGn\",\n",
    "                           range_color=(46, 205),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'Yield':'Yield'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\yield.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'figures\\\\CUE.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img1 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\GDD.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img2 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\prcp.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img3 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\EDD.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img4 = Image.open(location)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2,\n",
    "                        figsize=(20, 16))\n",
    "\n",
    "axs[0, 0].set_title('(a) CUE', fontsize = 25)\n",
    "axs[0, 0].imshow(img1)\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].set_title('(b) GDD', fontsize = 25)\n",
    "axs[0, 1].imshow(img2)\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "axs[1, 0].set_title('(c) Precipitation', fontsize = 25)\n",
    "axs[1, 0].imshow(img3)\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].set_title('(d) EDD', fontsize = 25)\n",
    "axs[1, 1].imshow(img4)\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'figures\\\\figure_2.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Corn CUE and yield responses to weather variables visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1. Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_yield_coef = []\n",
    "\n",
    "for i in corn_df_yield.fips.unique():\n",
    "    d = {}\n",
    "    df = corn_df_yield.loc[corn_df_yield.fips==i, ['Yield','edd','gdd','prcp']]\n",
    "    mod = smf.ols(formula='Yield ~ edd + gdd + prcp', \\\n",
    "              data=df, missing='drop')\n",
    "    res = mod.fit()\n",
    "    d['fips'] = i\n",
    "    d['edd'] = res.params.edd\n",
    "    d['gdd'] = res.params.gdd\n",
    "    d['prcp'] = res.params.prcp\n",
    "    d['edd_p'] = res.pvalues.edd\n",
    "    d['gdd_p'] = res.pvalues.gdd\n",
    "    d['prcp_p'] = res.pvalues.prcp\n",
    "    corn_yield_coef.append(d)\n",
    "\n",
    "corn_yield_coef = pd.DataFrame(corn_yield_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_cue_coef = []\n",
    "\n",
    "for i in corn_df_cue.fips.unique():\n",
    "    d = {}\n",
    "    df = corn_df_cue.loc[corn_df_cue.fips==i, ['CUE','edd','gdd','prcp']]\n",
    "    mod = smf.ols(formula='CUE ~ edd + gdd + prcp', \\\n",
    "              data=df, missing='drop')\n",
    "    res = mod.fit()\n",
    "    d['fips'] = i\n",
    "    d['edd'] = res.params.edd\n",
    "    d['gdd'] = res.params.gdd\n",
    "    d['prcp'] = res.params.prcp\n",
    "    d['edd_p'] = res.pvalues.edd\n",
    "    d['gdd_p'] = res.pvalues.gdd\n",
    "    d['prcp_p'] = res.pvalues.prcp\n",
    "    corn_cue_coef.append(d)\n",
    "\n",
    "corn_cue_coef = pd.DataFrame(corn_cue_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corn_CUE_Yield_coef = corn_cue_coef.merge(corn_yield_coef, on=['fips'], suffixes=('_CUE', '_yield'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Corn_CUE_Yield_coef)):\n",
    "    if Corn_CUE_Yield_coef.loc[i,'gdd_yield']>0 and Corn_CUE_Yield_coef.loc[i,'gdd_CUE']>0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'gdd_category'] = '++'\n",
    "    elif Corn_CUE_Yield_coef.loc[i,'gdd_yield']>0 and Corn_CUE_Yield_coef.loc[i,'gdd_CUE']<0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'gdd_category'] = '+-'\n",
    "    elif Corn_CUE_Yield_coef.loc[i,'gdd_yield']<0 and Corn_CUE_Yield_coef.loc[i,'gdd_CUE']>0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'gdd_category'] = '-+'\n",
    "    else:\n",
    "        Corn_CUE_Yield_coef.loc[i,'gdd_category'] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(Corn_CUE_Yield_coef, geojson=counties, locations='fips', color='gdd_category',\n",
    "                    color_discrete_map={'++':'red', '--':'blue', '+-':'yellow', '-+':'#00CC96'},\n",
    "                    scope=\"usa\",\n",
    "                    labels={'gdd_category':'Yield/CUE'}\n",
    "                    )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\gdd_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Corn_CUE_Yield_coef)):\n",
    "    if Corn_CUE_Yield_coef.loc[i,'prcp_yield']>0 and Corn_CUE_Yield_coef.loc[i,'prcp_CUE']>0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'prcp_category'] = '++'\n",
    "    elif Corn_CUE_Yield_coef.loc[i,'prcp_yield']>0 and Corn_CUE_Yield_coef.loc[i,'prcp_CUE']<0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'prcp_category'] = '+-'\n",
    "    elif Corn_CUE_Yield_coef.loc[i,'prcp_yield']<0 and Corn_CUE_Yield_coef.loc[i,'prcp_CUE']>0:\n",
    "        Corn_CUE_Yield_coef.loc[i,'prcp_category'] = '-+'\n",
    "    else:\n",
    "        Corn_CUE_Yield_coef.loc[i,'prcp_category'] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(Corn_CUE_Yield_coef, geojson=counties, locations='fips', color='prcp_category',\n",
    "                    color_discrete_map={'++':'red', '--':'blue', '+-':'yellow', '-+':'#00CC96'},\n",
    "                    scope=\"usa\",\n",
    "                    labels={'prcp_category':'Yield/CUE'}\n",
    "                    )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\prcp_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Corn_CUE_Yield_coef)):\n",
    "    if abs(Corn_CUE_Yield_coef.loc[i,'gdd_p_CUE'])<0.1 and abs(Corn_CUE_Yield_coef.loc[i,'gdd_p_yield'])<0.1:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category'] = 'both'\n",
    "    elif abs(Corn_CUE_Yield_coef.loc[i,'gdd_p_CUE'])<0.1:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category'] = 'CUE'\n",
    "    elif abs(Corn_CUE_Yield_coef.loc[i,'gdd_p_yield'])<0.1:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category'] = 'yield'\n",
    "    else:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(Corn_CUE_Yield_coef.dropna(subset=['sig_category']), \n",
    "                    geojson=counties, \n",
    "                    locations='fips', \n",
    "                    color='sig_category',\n",
    "                    color_discrete_map={'both':'purple', \n",
    "                                        'CUE':'blue', \n",
    "                                        'yield':'red'},\n",
    "                    scope=\"usa\",\n",
    "                    labels={'sig_category':'Significance'}\n",
    "                    )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\sig_gdd_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Corn_CUE_Yield_coef)):\n",
    "    if abs(Corn_CUE_Yield_coef.loc[i,'prcp_p_CUE'])<0.2 and abs(Corn_CUE_Yield_coef.loc[i,'prcp_p_yield'])<0.2:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category_prcp'] = 'both'\n",
    "    elif abs(Corn_CUE_Yield_coef.loc[i,'prcp_p_CUE'])<0.2:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category_prcp'] = 'CUE'\n",
    "    elif abs(Corn_CUE_Yield_coef.loc[i,'prcp_p_yield'])<0.2:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category_prcp'] = 'yield'\n",
    "    else:\n",
    "        Corn_CUE_Yield_coef.loc[i,'sig_category_prcp'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(Corn_CUE_Yield_coef.dropna(subset=['sig_category_prcp']), \n",
    "                    geojson=counties, \n",
    "                    locations='fips', \n",
    "                    color='sig_category_prcp',\n",
    "                    color_discrete_map={'both':'purple', \n",
    "                                        'CUE':'blue', \n",
    "                                        'yield':'red'},\n",
    "                    scope=\"usa\",\n",
    "                    labels={'sig_category_prcp':'Significance'}\n",
    "                    )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(font=dict(size=20, color='black'))\n",
    "fig.show()\n",
    "filename = 'figures\\\\sig_prcp_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.write_image(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'figures\\\\gdd_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img1 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\prcp_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img2 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\sig_gdd_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img3 = Image.open(location)\n",
    "\n",
    "filename = 'figures\\\\sig_prcp_yield_cue.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "img4 = Image.open(location)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2,\n",
    "                        figsize=(20, 16))\n",
    "\n",
    "axs[0, 0].set_title('(a) Yield and CUE vs. GDD', fontsize = 25)\n",
    "axs[0, 0].imshow(img1)\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].set_title('(b) Yield and CUE vs precipitation', fontsize = 25)\n",
    "axs[0, 1].imshow(img2)\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "axs[1, 0].set_title('(c) GDD significance level', fontsize = 25)\n",
    "axs[1, 0].imshow(img3)\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].set_title('(d) Precipitation significance level', fontsize = 25)\n",
    "axs[1, 1].imshow(img4)\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'figures\\\\figure_4.png'\n",
    "location = os.path.join(cwd, filename)\n",
    "fig.savefig(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
